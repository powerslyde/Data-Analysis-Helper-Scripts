{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the external packages into Python to perform various analyses\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import punkt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import json\n",
    "import pymssql as pym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import custom functions\n",
    "from cleanString import cleanString\n",
    "from createStopWords import createStopWords\n",
    "from fileDataLoad import fileDataLoad\n",
    "from WarehouseDataExtract import WarehouseDataExtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using my test star wars dataset - if this was a real analysis you would use another source file, \n",
    "# either from Excel, CSV or the AMS Warehouse using WarehouseData Extract\n",
    "#filename = r'C:\\Users\\jpuryear1\\Documents\\Python Scripts\\starwars_data.xlsx'\n",
    "#sheetname = 'Sheet1'\n",
    "#inputDF = fileDataLoad(filename,sheetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the EAI code that you would like to generate a Top Terms List for:  10966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are pulling data for 10966\n",
      "There are 428 observations and 9 features in this dataset. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports the JSON file with User Id and Password\n",
    "db_data = json.load(open(r'c:\\Users/jpuryear1/Documents/Python Scripts/DB_connection.json'))\n",
    "# Extracts user id and password to variables\n",
    "WH_USER = db_data['userid']\n",
    "WH_PW = db_data['password']\n",
    "#EAI code to be queried\n",
    "#print('Welcome to Incident Wordcloud Generation!')\n",
    "eai_cd = input('Please type in the EAI code that you would like to generate a Top Terms List for: ')\n",
    "print(f'You are pulling data for {eai_cd}')\n",
    "#print('Data Extract Commencing - Please note that it will take several minutes to pull the data')\n",
    "#Standard SQL to pull data for a given EAI Code\n",
    "sql = f\"\"\"SELECT number, short_description, description, u_resolution_notes, u_incident_resolution_category, \n",
    "u_incident_resolution_subcateg, close_code, contact_type\n",
    "  FROM [USBPMMetricsWhse].[dbo].[T_SRVNW_INCDN_SUM] a\n",
    "  JOIN [USBPMMetricsWhse].[dbo].[T_SRVNW_AFCT_TASK_CI_SUM] b on a.number = b.task\n",
    "  WHERE\n",
    "  a.DW_REC_CUR_IND = 'Y'\n",
    "  and b.ci_item like '{eai_cd}%'\n",
    "  and a.opened_at > '2019-01-01 00:00:00'\"\"\"\n",
    "# runs the WarehouseDataExtract function and imports the data to a dataframe\n",
    "inputDF = WarehouseDataExtract(WH_USER, WH_PW, sql)\n",
    "# print the head so you know which column to pull the text data from\n",
    "inputDF['Summary'] = inputDF['short_description'].astype(str) + ' - ' + inputDF['description'].astype(str) + ' - ' + inputDF['u_resolution_notes'].astype(str)\n",
    "print(f\"There are {inputDF.shape[0]} observations and {inputDF.shape[1]} features in this dataset. \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Summary data from the dataframe into a list\n",
    "TextReviewList = inputDF.loc[:,'Summary'].tolist()\n",
    "\n",
    "#Create a \"clean\" list to hold the cleaned strings\n",
    "TextCleanList = []\n",
    "\n",
    "# Clean the strings from TextReviewList and copy the clean strings to TextCleanList\n",
    "for str in TextReviewList:\n",
    "    TextCleanList.append(cleanString(str))\n",
    "    \n",
    "# adds a new column to the inputDF to hold the cleaned summary text\n",
    "inputDF['CleanText'] = ''\n",
    "\n",
    "# merge the cleaned summary back into the input dataframe\n",
    "inputDF['CleanText'] = pd.Series(TextCleanList).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Stop words to use\n",
    "remove_words = ('entered', 'auto', 'ams', 'arm', 'metlife', 'l1', 'us', 'corporate', 'billing', 'system', 'byauto','aalert', 'f090', 'e90', 'gssp', 'platformentered'\n",
    "               ,'com', 'https', 'gto', 'bmc', 'servicing', 'platform', 'topaz')\n",
    "stopset = createStopWords(remove_words)\n",
    "\n",
    "#need more information about what this does...\n",
    "vectorizer = TfidfVectorizer(stop_words=stopset, analyzer = 'word')\n",
    "#need more information about what this does...\n",
    "tfidf_matrix = vectorizer.fit_transform(inputDF.loc[:,'CleanText'].tolist())\n",
    "\n",
    "# break out the distinct words\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = tfidf_matrix.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "#convert the Df dataframe to True / False values\n",
    "df_boo = (df.loc[:] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to group all tickets by - ideally this might be a period or cluster value\n",
    "df_boo['Grouping'] = 'All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00003</th>\n",
       "      <th>0001</th>\n",
       "      <th>00094488755</th>\n",
       "      <th>004</th>\n",
       "      <th>00403745728</th>\n",
       "      <th>00455964021</th>\n",
       "      <th>00592858443</th>\n",
       "      <th>00821638284</th>\n",
       "      <th>...</th>\n",
       "      <th>yikes</th>\n",
       "      <th>ykhh9vgprqlu964pgacjucg0kxem4cm9tmaztt4kp9hczuqhtpilswmvwnwnkwusu3vhja4acbmgc1s6xcead7qpblfvkhl6vd3ge</th>\n",
       "      <th>yoshito</th>\n",
       "      <th>yxxzfgvctbsmcxgryui6nneec5gsrt7fvfpsv4</th>\n",
       "      <th>zelno</th>\n",
       "      <th>zgtjlsy0pzntw8qihyk9adcbuws6twcgz7fdlbzity</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zipdeliveryofficecode</th>\n",
       "      <th>zztestge123</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grouping</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>1.869159</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>1.401869</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.233645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                00       000     00003      0001  00094488755       004  \\\n",
       "Grouping                                                                  \n",
       "All       0.700935  0.934579  1.869159  0.233645     0.233645  0.233645   \n",
       "\n",
       "          00403745728  00455964021  00592858443  00821638284     ...       \\\n",
       "Grouping                                                         ...        \n",
       "All          0.233645     0.233645     0.233645     0.233645     ...        \n",
       "\n",
       "             yikes  \\\n",
       "Grouping             \n",
       "All       0.233645   \n",
       "\n",
       "          ykhh9vgprqlu964pgacjucg0kxem4cm9tmaztt4kp9hczuqhtpilswmvwnwnkwusu3vhja4acbmgc1s6xcead7qpblfvkhl6vd3ge  \\\n",
       "Grouping                                                                                                          \n",
       "All                                                0.233645                                                       \n",
       "\n",
       "           yoshito  yxxzfgvctbsmcxgryui6nneec5gsrt7fvfpsv4     zelno  \\\n",
       "Grouping                                                               \n",
       "All       0.233645                                0.233645  1.401869   \n",
       "\n",
       "          zgtjlsy0pzntw8qihyk9adcbuws6twcgz7fdlbzity       zip   zipcode  \\\n",
       "Grouping                                                                   \n",
       "All                                         0.233645  0.700935  0.233645   \n",
       "\n",
       "          zipdeliveryofficecode  zztestge123  \n",
       "Grouping                                      \n",
       "All                    0.233645     0.233645  \n",
       "\n",
       "[1 rows x 1812 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average the distribution of the given word across the dataset\n",
    "AllDist = df_boo.groupby(\"Grouping\").mean()*100\n",
    "AllDist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = AllDist.iloc[:, 1:].sum(axis=0)\n",
    "#print(words.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define each column as a pandas series\n",
    "wordList = pd.Series(words.index.values, index = np.arange(len(words)))\n",
    "wordDist = pd.Series(list(words), index = np.arange(len(words)))\n",
    "\n",
    "# create the dataframe\n",
    "wordDF = pd.DataFrame(dict(wordList = wordList, wordDist = wordDist))\n",
    "wordDF = wordDF[[\"wordList\", \"wordDist\"]]\n",
    "# remove words with values less than 1%\n",
    "wordDF = wordDF[wordDF['wordDist'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     wordList   wordDist\n",
      "0       error  82.943925\n",
      "1      online  75.467290\n",
      "2         msg  74.299065\n",
      "3      public  74.065421\n",
      "4        step  73.364486\n",
      "5       10966  73.130841\n",
      "6    critical  72.897196\n",
      "7   keepalive  71.962617\n",
      "8        html  71.495327\n",
      "9     content  70.794393\n",
      "10      match  70.560748\n",
      "11  servi001a  70.560748\n",
      "12     impact  57.242991\n",
      "13     closed  55.373832\n",
      "14    manager  55.373832\n",
      "15   original  54.906542\n",
      "16     events  54.906542\n",
      "17     please  35.747664\n",
      "18      taken  26.635514\n",
      "19    actions  26.168224\n",
      "20    provide  25.934579\n",
      "21   incident  25.700935\n",
      "22       done  24.766355\n",
      "23     action  24.299065\n",
      "24       took  24.065421\n"
     ]
    }
   ],
   "source": [
    "#sort in descending order\n",
    "wordDF.sort_values([\"wordDist\"], ascending=False, inplace=True)\n",
    "wordDF.reset_index(inplace=True, drop=True)\n",
    "# Print out the Top 25 Terms used at least once per Row\n",
    "print(wordDF.head(25))\n",
    "#print(wordDF.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
